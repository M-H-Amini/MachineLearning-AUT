{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLe-Lec2-LogisticRegression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjc5HVxoHy7pAR+fTr/Trl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-H-Amini/MachineLearning-AUT/blob/master/MLe_Lec2_LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOz2-2BTKSJG",
        "colab_type": "text"
      },
      "source": [
        "# In The Name Of ALLAH\n",
        "# Machine Learning *elementary* Course\n",
        "## Amirkabir University of Technology\n",
        "### Mohammad Hossein Amini (mhamini@aut.ac.ir)\n",
        "# Lecture 2 - Logistic Regression\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=144SDpgv7EEy6Og1ZFNIv_nBaugKGiSCE\" width=\"400\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdVQTDWntkM0",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "The theoretical stuff has been discussed in the video lectures. Let's implement a little...\n",
        "\n",
        "First of all, we should import some modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGuG9on8KIGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6OLgydb7yBK",
        "colab_type": "text"
      },
      "source": [
        "# Discovering Sigmoid\n",
        "Let's see **sigmoid** function in action."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95o_uqNF75jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1/(1 + np.exp(-x))\n",
        "\n",
        "\n",
        "x = np.linspace(-10, 10, 100)\n",
        "plt.figure()\n",
        "plt.plot(x, sigmoid(x), 'r')\n",
        "plt.title(r'$\\sigma (x) = \\frac{1}{1+e^{-x}} $', fontsize = 30)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjVe4qSOEG5G",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1SdMUDfOhtOsfDMiDVsE4InR5fVSOAvF2\" width=\"300\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3fGo5XZKO1F",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression (Hand Coding!)\n",
        "Let's implement some simple examples just using **numpy**!\n",
        "\n",
        "First of all, let's create a simple dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EoUpLt9KRwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0], [0], [0], [1]])\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3NIjtfwReA9",
        "colab_type": "text"
      },
      "source": [
        "A simple function to show the situation can be so helpful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjr4hq_QKjT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show(x, y, w=None):\n",
        "  label = {0: 'ro', 1: 'bx'}\n",
        "  plt.figure()\n",
        "  for i in range(y.shape[0]):\n",
        "    plt.plot(x[i, 0], x[i, 1], label[y[i, 0]])\n",
        "  if w is not None:\n",
        "    p1 = (0, -w[0, 0]/w[2, 0])\n",
        "    p2 = (-w[0, 0]/w[1, 0], 0)\n",
        "    plt.plot([p1[0], p2[0]], [p1[1], p2[1]], 'g')\n",
        "  plt.show()\n",
        "\n",
        "w = np.array([[-0.5], [0.1], [1]])\n",
        "show(x, y, w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vavx2dwsRsx5",
        "colab_type": "text"
      },
      "source": [
        "Just like the **Linear Regression** Notebook, we implement functions **h** and **train_step**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_XHV-lUMce2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha = 0.1\n",
        "def h(x, w, has_bias = True):\n",
        "  if not has_bias:\n",
        "    x = np.concatenate((np.ones((x.shape[0], 1)), x), axis=1)\n",
        "  return sigmoid(np.dot(x, w))\n",
        "def train_step(x, y, w):\n",
        "  x = np.concatenate((np.ones((x.shape[0], 1)), x), axis=1)\n",
        "  w = w + alpha*np.dot(x.T , (y-h(x, w)))\n",
        "  return w\n",
        "\n",
        "print('Before: ', w.T)\n",
        "w = train_step(x[0:1, :], y[0:1, :], w)\n",
        "print('After: ', w.T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6R1TzZ2z1I9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#index = np.random.randint(0, y.shape[0])\n",
        "alpha = 0.1\n",
        "index = 3\n",
        "w = train_step(x[index:index+1, :], y[index:index+1, :], w)\n",
        "show(x, y, w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKHMYBKiPFO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha = 0.03\n",
        "for i in range(100):\n",
        "  index = np.random.randint(0, y.shape[0])\n",
        "  w = train_step(x[index:index+1, :], y[index:index+1, :], w)\n",
        "\n",
        "show(x, y, w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9WtijAvtqcv",
        "colab_type": "text"
      },
      "source": [
        "# Importing Dataset\n",
        "Today, we'll be using **Heart Disease UCI** dataset. It predicts the likelihood of a patient having heart disease. Let's import it in our program."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km5imCPJOq4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = pd.read_csv('heart.csv')\n",
        "ds.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBub1acgSEOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds = pd.read_csv('heart.csv')\n",
        "ds = ds.sample(frac=1).reset_index(drop=True)\n",
        "a = pd.get_dummies(ds['cp'], prefix='cp')\n",
        "b = pd.get_dummies(ds['slope'], 'slope')\n",
        "c = pd.get_dummies(ds['thal'], 'thal')\n",
        "ds = pd.concat([ds, a, b, c], axis=1)\n",
        "ds = ds.drop(columns=['cp', 'slope', 'thal'])\n",
        "y = np.array(ds['target'])\n",
        "y = y[:, np.newaxis]\n",
        "ds = ds.drop(columns=['target'])\n",
        "x = np.array(ds)\n",
        "#maximum = np.array(ds.max())\n",
        "#ds = ds/maximum\n",
        "ds.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHI1cbbab9kd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split = 0.8\n",
        "no_of_trains = int(ds.shape[0]*split)\n",
        "X_train = x[:no_of_trains, :]\n",
        "Y_train = y[:no_of_trains, :]\n",
        "X_test = x[no_of_trains:, :]\n",
        "Y_test = y[no_of_trains:, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l177vmFB7ZeN",
        "colab_type": "text"
      },
      "source": [
        "# Tensorflow Codes\n",
        "Our implementation in tensorflow is much like the previous session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuWzgyJ7Q7yK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.constant(X_train, dtype=tf.float32)\n",
        "Y = tf.constant(Y_train, dtype=tf.float32)\n",
        "\n",
        "w = tf.Variable(np.random.randn(X.shape[1]+1, 1), dtype=tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVjLdquVOCn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def h(x, w):\n",
        "  x = tf.concat((tf.ones((x.shape[0], 1)), x), axis=1)\n",
        "  return tf.sigmoid(tf.matmul(x,w))\n",
        "\n",
        "def cost(x, y, w):\n",
        "  return tf.reduce_mean(tf.losses.binary_crossentropy(y, h(x, w)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDrGNE9KMgai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.optimizers.Adam()\n",
        "#w = tf.Variable(np.random.randn(X.shape[1]+1, 1)/1000, dtype=tf.float32)\n",
        "w = tf.Variable(np.zeros((X.shape[1]+1, 1)), dtype=tf.float32)\n",
        "\n",
        "def train_step(x, y, w, verbose=0):\n",
        "  with tf.GradientTape() as t:\n",
        "    J = cost(x, y, w)\n",
        "  if verbose:\n",
        "    print('Loss: {}'.format(J))\n",
        "  w_grads = t.gradient(J, w)\n",
        "  optimizer.apply_gradients(zip([w_grads], [w]))\n",
        "  return w\n",
        "\n",
        "print('Before: ', w)\n",
        "w = train_step(X[index:index+1, :], Y[index:index+1, :], w, verbose = 1)\n",
        "print('After: ', w)\n",
        "print(cost(X, Y, w))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21vhsKv1FSHY",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=17X8qdM19JAlv53hlNJSolrRjXYfaOel-\" width=\"300\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LRl5CbgVpLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(X, Y, max_iters=1000, min_cost=0.01, w=None, verbose=0):\n",
        "  if w is None:\n",
        "    w = tf.Variable(np.random.randn(X.shape[1]+1, 1), dtype=tf.float32)\n",
        "  for i in range(max_iters):\n",
        "    index = np.random.randint(0, X.shape[0])\n",
        "    w = train_step(X[index:index+1, :], Y[index:index+1, :], w)\n",
        "    if verbose:\n",
        "      print('Cost: ', cost(X, Y, w).numpy())\n",
        "  print(\"Training Done...\")\n",
        "  print(\"Cost: {}\".format(cost(X, Y, w).numpy()))\n",
        "  print(\"w = \", w)\n",
        "  return w\n",
        "\n",
        "w = train(X, Y, w=w, max_iters=1000, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D48ersedu_rY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = h(X_test, w)\n",
        "for i in range(X_test.shape[0]):\n",
        "  print('No {:2}, Target: {}, Output: {:.2f}'.format(i+1, Y_test[i,0], predictions.numpy()[i,0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duYF5G0I2y_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corrects = 0\n",
        "wrongs = 0\n",
        "for i in range(Y_test.shape[0]):\n",
        "  if abs(Y_test[i, 0] - predictions.numpy()[i, 0])<=0.5:\n",
        "    corrects += 1\n",
        "  else:\n",
        "    wrongs += 1\n",
        "\n",
        "print(f'Corrects: {corrects}, Wrongs: {wrongs}')\n",
        "print('Accuracy: {}'.format(corrects/(corrects + wrongs)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}