{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLe-Lec6-PCA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMk7bUkmkHGjZlPpwm/6yJm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-H-Amini/MachineLearning-AUT/blob/master/MLe_Lec6_PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGcKAh8AGaQR",
        "colab_type": "text"
      },
      "source": [
        "# In The Name Of ALLAH\n",
        "# Machine Learning *elementary* Course\n",
        "## Amirkabir University of Technology\n",
        "### Mohammad Hossein Amini (mhamini@aut.ac.ir)\n",
        "# Lecture 6 - Principal Component Analysis\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=144SDpgv7EEy6Og1ZFNIv_nBaugKGiSCE\" width=\"400\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOq3gzVdaJVK",
        "colab_type": "text"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "In this project I'm gonna compress an image using the famous **Principal Component Analysis** or **PCA**. There are plenty of useful resources and textbooks to study the algorithm. In summary, We'll be partitioning the image into non-overlapping windows (for example of size 8$*$8). So after flattening each window, we have a column vector (64$*$1 in this case) for each window. By concatenating all these windows we have a big matrix, **X**, in which each column is a flattened window. PCA theory, in a statistical view, simply says that if we want to project each sample (window vector in our case) in a direction such that we have the most variance in that direction, we must project samples in the direction of the eigenvectors of the covariance matrix of the samples (**cov(X)**). So we can say, in some senses, that we have the most information in the direction of the eigenvectors of the covariance matrix of the data. \n",
        "\n",
        "I will use the image of my favorite mathematician, Gilbert Strang, Wishing him a long and healthy life.\n",
        "\n",
        "Let's compress the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5urFQjJBzrYX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "We can do all our job with *cv2* and *numpy*, but we'll use *matplotlib* for displaying results here in the colab or in your IDE and *os* for a comaprison of sizes in the original and comressed images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrk9WCk1Z1vy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQEeBE3Gz568",
        "colab_type": "text"
      },
      "source": [
        "# Turning The Image Into Windows\n",
        "As I told you, first of all we turn our image into a bunch of non-overlapping windows of arbitrary size. So I'll implement **windowize** function such that it gets the image numpy array and the arbitrary size and turns the image into windows of that size. One of the assumptions of the *PCA* theorem is that samples are zero-mean. In case they aren't really zero-mean, we can simply subtract their mean from them without losing any generality. In the end we can add this mean again so that everything becomes ok! We would also normalize our data so that all of them are in the range of 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b6gtwDPa5ru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def windowize(image, size=(8, 8)):\n",
        "  X = np.zeros((size[0]*size[1], 1))\n",
        "  for i in range(image.shape[0]//size[0]):\n",
        "    for j in range(image.shape[1]//size[1]):\n",
        "      window = image[i*size[0]:(i+1)*size[0], j*size[1]:(j+1)*size[1]]\n",
        "      window = np.reshape(window, (-1, 1))  #  Flattening the window into a column vector...\n",
        "      X = np.concatenate((X, window), axis=1)\n",
        "  X = X[:, 1:]/255.  #  Normalizing data...\n",
        "  X -= np.reshape(np.mean(X, axis=1), (-1, 1))\n",
        "  return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byMJr9KQ1t6w",
        "colab_type": "text"
      },
      "source": [
        "#  Turning All Windows Into An Image\n",
        "As we've been able to turn an image into windows, we must also be able to turn all windows beside each other and reconstruct the image again! So we implement the **dewindowize** function. It gets the big matrix of all windows in its columns and the number of windows in each row and column of the image as a tupple (for example (50,50) for an image with 50 windows in each column and each row). It also gets the window size. Finally it return the image numpy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a4l4lI9wycr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dewindowize(X, window_no, window_size=(8, 8)):\n",
        "  image = np.zeros((window_no[0]*window_size[0], window_no[1]*window_size[1]))\n",
        "  c = 0\n",
        "  for i in range(window_no[0]):\n",
        "    for j in range(window_no[1]):\n",
        "      image[i*window_size[0]:(i+1)*window_size[0], j*window_size[1]:(j+1)*window_size[1]] = np.reshape(X[:, c:c+1], window_size)\n",
        "      c+=1\n",
        "  return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gks0Wjht3F-e",
        "colab_type": "text"
      },
      "source": [
        "In the following code we simply turn an image into windows of $8*8$ and reconstruct it again. Let's see how it works..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CFLakde3LCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = cv2.imread('gilbert.jpeg', 0)\n",
        "window_size = (8, 8)\n",
        "window_no = (image.shape[0]//window_size[0], image.shape[1]//window_size[1])\n",
        "X = windowize(image, window_size)\n",
        "dewindowized_image = dewindowize(X, window_no, window_size)\n",
        "plt.figure()\n",
        "plt.title('Dewindowized Image')\n",
        "plt.imshow(dewindowized_image, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiWSjQDIeKIa",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1PFj6vX9sTt5rg3PATA7C_VtMwA5mCqZT\" width=\"400\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gQrZyEN4Bvm",
        "colab_type": "text"
      },
      "source": [
        "#  PCA Stuff\n",
        "Now let's implement **PCA**. First of all, we'll implement **PCA** function. It gets data matrix(X in our case) such that each column of X is a sample. After finding their covariance matrix, we would find the eigenvectors and eigenvalues of the covariance matrix. So, again, by the PCA theorem we know that we have the most variance in projecting in the direction of the eigenvector with the most corresponding eigenvalue. We have the second most variance in projecting in the direction of the eigenvector with the second most corresponding eigenvalue. We just need the **n** eigencvectors (calling them principal axes) with n top corresponding eigenvalues. So our **PCA** function returns these eigenvectors with their corresponding eigenvalues."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5swmfVx4Lfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def PCA(X, n):\n",
        "  #  Finding covariance matrix...\n",
        "  cov = np.dot(X, np.transpose(X))/X.shape[1]\n",
        "  #  Finding eigenvalues and eigenvectors of the covariance matrix...\n",
        "  evals, evecs = np.linalg.eig(cov)\n",
        "  evecs = evecs.astype(float)\n",
        "  evals = evals.astype(float)\n",
        "  top_indexes = evals.argsort()[-n:][::-1]\n",
        "  return evecs[:, top_indexes], evals[top_indexes]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bnkb0tPh5tKh",
        "colab_type": "text"
      },
      "source": [
        "After finding principal axes and their corresponding eigenvalues, we must be able to project our data in their direction. So we have **transform** function that gets data and principal axes and projects data in those principal axes to get the **principal components**. Note that no matter you give this function a single sample (column vector) or a big matrix of data, it gives you the correct result!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIGQQxRG5t6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transform(x, paxis):\n",
        "  return np.dot(np.transpose(paxis), x) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQZdo7XA6l86",
        "colab_type": "text"
      },
      "source": [
        "We must also be able to turn our principal components into original data (with high accuracy only, not full reconstrucion! Why? ;-)). So we implement **itransform** function. It gets principal components and principal axes and generates original data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMb9uBk36mLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def itransform(x, paxis):\n",
        "  return np.dot(paxis, x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaLGFM007gIY",
        "colab_type": "text"
      },
      "source": [
        "Now let's find the principal axes and principal components of our windows! We just keep, for example, 10 largest of them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xrc_LvZh7gT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "paxis, pvals = PCA(X, 5)\n",
        "X_transformed = transform(X, paxis)\n",
        "print(X_transformed.shape)\n",
        "X_itransformed = itransform(X_transformed, paxis)\n",
        "print(X_itransformed.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGghA3R_78b5",
        "colab_type": "text"
      },
      "source": [
        "Now we reconstruct our image with the itransformed data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt2ad8oj8EQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_reconstructed = dewindowize(X_itransformed, window_no, window_size)\n",
        "plt.figure()\n",
        "plt.title('Reconstructed Image')\n",
        "plt.imshow(image_reconstructed, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG6Ukthx9A4J",
        "colab_type": "text"
      },
      "source": [
        "# All-In-One!\n",
        "Let's do all the job in one function! We'll implement **compress** function. It gets an image and number of principal axes to compress the image with, **n** and window_sizes, and returns the compressed image. Isn't that amazing?!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVQIPHd99hWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compress(image, n, window_size=(8,8)):\n",
        "  window_no = (image.shape[0]//window_size[0], image.shape[1]//window_size[1])\n",
        "  X = windowize(image, window_size)\n",
        "  paxis, pvals = PCA(X, n)\n",
        "  X_transformed = transform(X, paxis)\n",
        "  X_itransformed = itransform(X_transformed, paxis)\n",
        "  image_reconstructed = dewindowize(X_itransformed, window_no, window_size)\n",
        "  return image_reconstructed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eizdWUC7-VBx",
        "colab_type": "text"
      },
      "source": [
        "# Test\n",
        "Let's have a final test over our work!\n",
        "\n",
        "We'll compress our image with different number of principal components and see the effect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwPoxCY_-ng6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = cv2.imread('gilbert.jpeg', 0)\n",
        "print('Original size: ', os.path.getsize('gilbert.jpeg'))\n",
        "ns = [i+1 for i in range(10)]\n",
        "for i in ns:\n",
        "  image_compressed = compress(image, i)\n",
        "  cv2.imwrite('Compressed{}.jpg'.format(i), image_compressed)\n",
        "  print('n: ', i, 'size:' , os.path.getsize('Compressed{}.jpg'.format(i)))\n",
        "  plt.figure()\n",
        "  plt.title('Compressed with {} Principal Components'.format(i))\n",
        "  plt.imshow(image_compressed, cmap='gray')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5RAo5WbeU1C",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1c4tkdZzmJqFTtAmUq3xmoYgzJ3hgsopc\" width=\"400\">\n"
      ]
    }
  ]
}