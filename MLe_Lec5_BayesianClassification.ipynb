{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLe-Lec5-SpamClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPo/58pEG/CRnL7covxjieH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-H-Amini/MachineLearning-AUT/blob/master/MLe_Lec5_SpamClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_v4yTIjfigI",
        "colab_type": "text"
      },
      "source": [
        "# In The Name Of ALLAH\n",
        "# Machine Learning *elementary* Course\n",
        "## Amirkabir University of Technology\n",
        "### Mohammad Hossein Amini (mhamini@aut.ac.ir)\n",
        "# Lecture 5 - Bayesian Classification\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=144SDpgv7EEy6Og1ZFNIv_nBaugKGiSCE\" width=\"400\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk9F9UeAfrec",
        "colab_type": "text"
      },
      "source": [
        "# Spam Classification\n",
        "Using a relatively tiny dataset of emails, with some really bad assumptions, we would build a spam classifier and see its performance. Today, we will just use **glob** and **numpy**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4N40WLiMGL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GsLDIQMgF54",
        "colab_type": "text"
      },
      "source": [
        "## Preparing Dataset\n",
        "Let us prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m8qwk8pMXEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip EmailsTrainingSet.zip > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8lw6PEIMcLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_spam_files = glob.glob('TrainingSet/sp*.txt')\n",
        "train_ham_files = glob.glob('TrainingSet/[!s]*.txt')\n",
        "test_spam_files = glob.glob('TestSet/sp*.txt')\n",
        "test_ham_files = glob.glob('TestSet/[!s]*.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0Y9lVYZ61fS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(train_spam_files), len(train_ham_files))\n",
        "print(len(test_spam_files), len(test_ham_files))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hicP8pEBgRTR",
        "colab_type": "text"
      },
      "source": [
        "## Estimating Parameters Of The Classifier\n",
        "We store words and their frequency in two dictionaries, one for spams and one for hams. We also implement the **updateDict** function such that it gets an email file and a dictionary and updates the dictionary with the content of the given email."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pizbRHuHNNi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spam_dict = {}\n",
        "ham_dict = {}\n",
        "spam_no = len(train_spam_files)\n",
        "ham_no = len(train_ham_files)\n",
        "spam_words_no = 0\n",
        "ham_words_no = 0\n",
        "\n",
        "def updateDict(file, dictionary, show_details=False):\n",
        "  with open(file) as f:\n",
        "    content = f.read()\n",
        "  words = content.split()\n",
        "  \n",
        "  if show_details:\n",
        "    print('Content: ', content)\n",
        "    print('Words: ', words)\n",
        "    \n",
        "  for word in words:\n",
        "    if word in dictionary.keys():\n",
        "      dictionary[word] = dictionary[word] + 1\n",
        "    else:\n",
        "      dictionary[word] = 1\n",
        "  \n",
        "for email in train_spam_files:\n",
        "  updateDict(email, spam_dict)\n",
        "\n",
        "for email in train_ham_files:\n",
        "  updateDict(email, ham_dict)\n",
        "\n",
        "for (key, value) in spam_dict.items():\n",
        "  spam_words_no += value\n",
        "\n",
        "for (key, value) in ham_dict.items():\n",
        "  ham_words_no += value\n",
        "\n",
        "spam_dict[0] = spam_words_no\n",
        "ham_dict[0] = ham_words_no\n",
        "print(spam_dict)\n",
        "print(ham_dict)\n",
        "print(spam_words_no, ham_words_no)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU5-jUoOUO2G",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1KfSj_4JzPe9Xvz4YXZcTzxHhcjo3_14Z\" width=\"700\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfJJ-Elrg_Ib",
        "colab_type": "text"
      },
      "source": [
        "## Building The Classifier\n",
        "**isSpam** function gets an email and predicts whether it's a spam or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSxHqtwiPxgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def isSpam(file, spam_dict, ham_dict, show_details=False):\n",
        "  with open(file) as f:\n",
        "    content = f.read()\n",
        "  words = content.split()\n",
        "  spam_prob = 0\n",
        "  ham_prob = 0\n",
        "\n",
        "  for word in words:\n",
        "    if word in spam_dict.keys():\n",
        "      spam_prob += np.log((spam_dict[word]+1) / (spam_dict[0] + len(spam_dict.keys())))\n",
        "    else:\n",
        "      spam_prob += np.log((1) / (spam_dict[0] + len(spam_dict.keys())))\n",
        "\n",
        "    if word in ham_dict.keys():\n",
        "      ham_prob += np.log((ham_dict[word]+1) / (ham_dict[0] + len(ham_dict.keys())))\n",
        "    else:\n",
        "      ham_prob += np.log((1) / (ham_dict[0] + len(ham_dict.keys())))\n",
        "    \n",
        "  if show_details:\n",
        "    print('Spam Probability: {}\\nHam Probability: {}'.format(spam_prob, ham_prob))\n",
        "  if spam_prob - ham_prob > 50:\n",
        "    return 1\n",
        "  return 0\n",
        "\n",
        "print(isSpam(train_ham_files[1], spam_dict, ham_dict, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RZjCHwUhLi7",
        "colab_type": "text"
      },
      "source": [
        "## Performance Evaluation\n",
        "For the evaluation of performance, we implement the **evaluate** function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ7nZ7fWUM49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(test_spam_files, test_ham_files, spam_dict, ham_dict, show_details=False):\n",
        "  spam_corrects = 0\n",
        "  spam_wrongs = 0\n",
        "  ham_corrects = 0\n",
        "  ham_wrongs = 0\n",
        "\n",
        "  for spam in test_spam_files:\n",
        "    predicted = isSpam(spam, spam_dict, ham_dict)\n",
        "    if predicted == 1:\n",
        "      spam_corrects += 1\n",
        "    else:\n",
        "      spam_wrongs += 1\n",
        "    if show_details:\n",
        "      print(f'Target: 1, Predicted: {predicted}')\n",
        "\n",
        "  for ham in test_ham_files:\n",
        "    predicted = isSpam(ham, spam_dict, ham_dict)\n",
        "    if predicted == 0:\n",
        "      ham_corrects += 1\n",
        "    else:\n",
        "      ham_wrongs += 1\n",
        "    if show_details:\n",
        "      print(f'Target: 0, Predicted: {predicted}')\n",
        "\n",
        "  print('Spam Accuracy: ', spam_corrects/(spam_corrects + spam_wrongs))\n",
        "  print('Ham Accuracy: ', ham_corrects/(ham_corrects + ham_wrongs))\n",
        "  print('Overall Accuracy: ', (spam_corrects + ham_corrects) / (spam_corrects + spam_wrongs + ham_corrects + ham_wrongs))\n",
        "\n",
        "evaluate(test_spam_files, test_ham_files, spam_dict, ham_dict, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ldltnx4UjpH",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1B8JvIcioH0a7W-zwFvceOm-bT_1x6YTS\" width=\"400\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgI3j4mTCYf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
